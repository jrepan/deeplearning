{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from time import time\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "It unzips *ballpatches_scaled.zip* and creates training and validation sets.\n",
    "\n",
    "<span style=\"color:red\">It's not necessary to run this, just unpack data.7z to get a subset of validation data.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_matches = ['34678777f7369acd1dcc4ccdaf1945ac', \n",
    "                      'ab6f78be30ce517d61422f41118c2eb4',\n",
    "                      '648b5d642ffc96cc23693b0bbe9c6cd7',\n",
    "                      'c9a72e59e447a605014c933547c4ecc7']\n",
    "os.mkdir('scaled')\n",
    "os.chdir('scaled')\n",
    "os.mkdir('training')\n",
    "os.mkdir('validation')\n",
    "os.chdir('training')\n",
    "myzip = zipfile.ZipFile('../../ballpatches_scaled.zip', 'r')\n",
    "myzip.extractall()\n",
    "for match in validation_matches:\n",
    "    shutil.move(match, '../validation/%s' % match)\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 224\n",
    "pixels_count = image_width**2\n",
    "input_channels = 3\n",
    "output_channels = 1\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters that are same for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 17\n",
    "momentum = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataset(Dataset):\n",
    "\tdef __init__(self, setname):\n",
    "\t\tself.filenames = glob('scaled/%s/*/*.png' % setname)\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.filenames)\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tdata = ndimage.imread(self.filenames[idx], flatten=False)\n",
    "\t\tdata = np.array(data, dtype=np.float)\n",
    "\t\tdata = np.swapaxes(data, 0, 2)\n",
    "\t\tarray = self.filenames[idx].split('_') # read correct ball coordinates that are written in file name\n",
    "\t\tx = float(array[-3])\n",
    "\t\ty = float(array[-2])\n",
    "\t\ttarget = torch.FloatTensor([x, y])\n",
    "\t\treturn data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\tdef __init__(self, hidden_layers, hidden_channels):\n",
    "\t\tglobal cuda\n",
    "\t\tsuper(Net, self).__init__()\n",
    "\t\tself.layers = []\n",
    "\t\tself.drops = []\n",
    "\t\tself.layers.append(nn.Conv2d(input_channels,  hidden_channels, kernel_size=kernel_size, padding = (kernel_size - 1)//2))\n",
    "\t\tself.drops.append(nn.Dropout2d(p = 0.1))\n",
    "\t\tif cuda:\n",
    "\t\t\tself.layers[-1] = self.layers[-1].cuda()\n",
    "\t\t\tself.drops[-1] = self.drops[-1].cuda()\n",
    "\t\tfor i in range(hidden_layers - 2):\n",
    "\t\t\tself.layers.append(nn.Conv2d(hidden_channels,  hidden_channels, kernel_size=kernel_size, padding = (kernel_size - 1)//2))\n",
    "\t\t\tself.drops.append(nn.Dropout2d(p = 0.1))\n",
    "\t\t\tif cuda:\n",
    "\t\t\t\tself.layers[-1] = self.layers[-1].cuda()\n",
    "\t\t\t\tself.drops[-1] = self.drops[-1].cuda()\n",
    "\t\tself.last_layer = nn.Conv2d(hidden_channels, output_channels, kernel_size=kernel_size, padding = (kernel_size - 1)//2)\n",
    "\t\tself.indices = Variable(torch.from_numpy(np.arange(image_width, dtype=np.float)).float(), requires_grad=False)\n",
    "\t\tif cuda:\n",
    "\t\t\tself.indices = self.indices.cuda()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tfor i in range(len(self.layers)):\n",
    "\t\t\tx = F.relu(self.drops[i](self.layers[i](x)))\n",
    "\t\tx = self.last_layer(x)\n",
    "\t\tx = x.view(-1, pixels_count)\n",
    "\t\tx = F.softmax(x, dim=1)\n",
    "\t\tx = x.view(-1, image_width, image_width)\n",
    "\n",
    "\t\txprob = torch.sum(x, dim=1) # sum probabilites to a vector\n",
    "\t\typrob = torch.sum(x, dim=2)\n",
    "\t\txcoord = torch.matmul(xprob, self.indices).view(-1) # get coordinate from weighted sum\n",
    "\t\tycoord = torch.matmul(yprob, self.indices).view(-1)\n",
    "\t\treturn torch.stack([xcoord, ycoord], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_accuracy = 0\n",
    "def test(model, model_name, do_save, loss_function, batch_size, dosave):\n",
    "\tglobal saved_accuracy\n",
    "    \n",
    "\ttxt_file = open('%s.txt' % model_name, 'w', 1) # 1 = line buffering\n",
    "\ttest_loader = DataLoader(SyntheticDataset('validation'), batch_size=batch_size)\n",
    "\n",
    "\tmodel.eval()\n",
    "\ttest_loss = 0\n",
    "\tcorrect = 0\n",
    "\tfor batch_idx, (data, target) in enumerate(test_loader):\n",
    "\t\tif cuda:\n",
    "\t\t\tdata, target = data.cuda(), target.cuda()\n",
    "\t\tdata, target = Variable(data, volatile=True), Variable(target.float())\n",
    "\t\toutput = model(data.float())\n",
    "\t\tcur_test_loss = loss_function(output, target, size_average=False).data[0] # sum up batch loss\n",
    "\t\ttest_loss += cur_test_loss\n",
    "\t\tcorrect += output.eq(target).cpu().sum()\n",
    "        \n",
    "\t\t# save txt file for plots\n",
    "\t\to = output.cpu().data.numpy()\n",
    "\t\tt = target.cpu().data.numpy()\n",
    "\t\tfor i in range(len(o)):\n",
    "\t\t\tprint('%d %d %d %d' % (o[i, 0], o[i, 1], t[i, 0], t[i, 1]), file=txt_file)\n",
    "\n",
    "\ttest_loss /= len(test_loader.dataset)\n",
    "\tcorrect = correct.data.numpy()[0]\n",
    "\taccuracy = 100. * correct / len(test_loader.dataset)\n",
    "\tprint('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), accuracy))\n",
    "    \n",
    "\t# Save model if it not worse\n",
    "\tif accuracy >= saved_accuracy and dosave:\n",
    "\t\ttorch.save(model.state_dict(), model_filename)\n",
    "\t\tsaved_accuracy = accuracy\n",
    "\t\tprint ('Model saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, hidden_layers, hidden_channels, batch_size, learning_rate, loss_function):\n",
    "    global saved_accuracy\n",
    "    \n",
    "    model = Net(hidden_layers, hidden_channels)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    train_loader = DataLoader(SyntheticDataset('training'), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    saved_accuracy = 0\n",
    "    while True:\n",
    "        try:\n",
    "            model.train()\n",
    "            start_time = time()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                if cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                data, target = Variable(data), Variable(target.float())\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data.float())\n",
    "                loss = loss_function(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                assert(not np.isnan(loss.cpu().data.numpy()))\n",
    "                print('Train Epoch: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "            print (time() - start_time, 's')\n",
    "\n",
    "            test(model, model_name, True, loss_function, batch_size, True)\n",
    "        except KeyboardInterrupt:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! These overwrite the saved weights files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train('A', 4, 16, 8, 0.0001, F.l1_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train('B', 10, 64, 32, 0.01, F.l1_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train('C', 10, 64, 32, 0.01, F.mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of already saved models and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_saved(model_name, hidden_layers, hidden_channels, batch_size, loss_function):\n",
    "\tmodel = Net(hidden_layers, hidden_channels)\n",
    "\tif cuda:\n",
    "\t\tmodel.cuda()\n",
    "\ttest(model, model_name, False, loss_function, batch_size, False)\n",
    "\n",
    "\tscale = 10 # how many pixels in one bin\n",
    "\tdata = np.loadtxt('%s.txt' % model_name)\n",
    "    \n",
    "\toutput_x = data[:, 0]\n",
    "\toutput_y = data[:, 1]\n",
    "\ttarget_x = data[:, 2]\n",
    "\ttarget_y = data[:, 3]\n",
    "\tx = np.arange(0, image_width + 1)\n",
    "\n",
    "\tplt.hist2d(output_x, target_x, range=[[0, image_width-1], [0, image_width-1]], bins=[image_width//scale, image_width//scale])\n",
    "\tplt.plot(x, x, 'r')\n",
    "\tplt.xlabel('x output')\n",
    "\tplt.ylabel('x target')\n",
    "\tplt.colorbar()\n",
    "\tplt.savefig('%s_x.pdf' % model_name)\n",
    "\tplt.close()\n",
    "\n",
    "\tplt.hist2d(output_y, target_y, range=[[0, image_width-1], [0, image_width-1]], bins=[image_width//scale, image_width//scale])\n",
    "\tplt.plot(x, x, 'r')\n",
    "\tplt.xlabel('y output')\n",
    "\tplt.ylabel('y target')\n",
    "\tplt.colorbar()\n",
    "\tplt.savefig('%s_y.pdf' % model_name)\n",
    "\tplt.close()\n",
    "\n",
    "\tdistance = np.sqrt(np.square(output_x - target_x) + np.square(output_y - output_y))\n",
    "\tplt.hist(distance, bins=image_width // scale)\n",
    "\tplt.xlabel('Distance')\n",
    "\tplt.ylabel('Count')\n",
    "\tplt.savefig('%s_distance.pdf' % model_name)\n",
    "\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 97.6653, Accuracy: 0/471 (0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_saved('A', 4, 16, 8, F.l1_loss)\n",
    "# results are in A_x.pdf, A_y.pdf and A_distance.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_saved('B', 10, 64, 32, F.l1_loss)\n",
    "# results are in B_x.pdf, B_y.pdf and B_distance.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_saved('C', 10, 64, 32, F.mse_loss)\n",
    "# results are in C_x.pdf, C_y.pdf and C_distance.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
